# CrawlerExample
Try developing some general crawlers
#### It's my first time to write crawler:)

## File introduction
* web_crawler.py crawler for web pages
* run.sh an example for forcing to restart the crawler task until it finished

## Functions already got:
1. read&write json files
2. random choosing headers
3. keep requesting webPage while the error occurs
4. sleep time increases as the error times increasing
5. wechat notify using <https://iyuu.cn>

## Todo list:
1. ip pools
2. multi threads
3. api-called crawler
4. collect methods to skip verify pages
5. maybe more ideas while my learning..
